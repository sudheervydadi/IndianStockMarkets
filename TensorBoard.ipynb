{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sudhe\\\\Desktop\\\\Stock Market Research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 25)                125       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                390       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 80        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 601\n",
      "Trainable params: 601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model=tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(4,)))\n",
    "    model.add(tf.keras.layers.Dense(25,activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(15,activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(5,activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])                         \n",
    "    return model\n",
    "\n",
    "model=build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3  target\n",
       "0   0   1   2   3       5\n",
       "1   4   5   6   7      10\n",
       "2   8   9  10  11      15\n",
       "3  12  13  14  15      20\n",
       "4  16  17  18  19      25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.arange(0,2000).reshape(-1,4)\n",
    "y=np.arange(5,(X.shape[0]+1)*5,5)\n",
    "\n",
    "temp=pd.DataFrame(data=X)\n",
    "temp['target']=pd.Series(y.reshape(-1,))\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.728590</td>\n",
       "      <td>-1.728590</td>\n",
       "      <td>-1.728590</td>\n",
       "      <td>-1.728590</td>\n",
       "      <td>-1.728590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.721662</td>\n",
       "      <td>-1.721662</td>\n",
       "      <td>-1.721662</td>\n",
       "      <td>-1.721662</td>\n",
       "      <td>-1.721662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.714734</td>\n",
       "      <td>-1.714734</td>\n",
       "      <td>-1.714734</td>\n",
       "      <td>-1.714734</td>\n",
       "      <td>-1.714734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.707806</td>\n",
       "      <td>-1.707806</td>\n",
       "      <td>-1.707806</td>\n",
       "      <td>-1.707806</td>\n",
       "      <td>-1.707806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.700877</td>\n",
       "      <td>-1.700877</td>\n",
       "      <td>-1.700877</td>\n",
       "      <td>-1.700877</td>\n",
       "      <td>-1.700877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3    target\n",
       "0 -1.728590 -1.728590 -1.728590 -1.728590 -1.728590\n",
       "1 -1.721662 -1.721662 -1.721662 -1.721662 -1.721662\n",
       "2 -1.714734 -1.714734 -1.714734 -1.714734 -1.714734\n",
       "3 -1.707806 -1.707806 -1.707806 -1.707806 -1.707806\n",
       "4 -1.700877 -1.700877 -1.700877 -1.700877 -1.700877"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "inputs_standardizer=StandardScaler()\n",
    "inputs_standardizer.fit_transform(temp.drop('target',axis=1).values.tolist())\n",
    "\n",
    "target_standardizer=StandardScaler()\n",
    "target_standardizer.fit_transform(temp['target'].values.reshape(-1,1).tolist())\n",
    "\n",
    "norm_temp=pd.DataFrame(data=inputs_standardizer.fit_transform(temp.drop('target',axis=1).values.tolist()))\n",
    "norm_temp['target']=pd.Series(target_standardizer.fit_transform(temp['target'].values.reshape(-1,1).tolist()).reshape(-1,))\n",
    "norm_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = temp.sample(frac=0.8,random_state=0)\n",
    "test_dataset = temp.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>577.927331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499.00</td>\n",
       "      <td>998.0</td>\n",
       "      <td>1497.00</td>\n",
       "      <td>1996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>577.927331</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500.00</td>\n",
       "      <td>999.0</td>\n",
       "      <td>1498.00</td>\n",
       "      <td>1997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>577.927331</td>\n",
       "      <td>2.0</td>\n",
       "      <td>501.00</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1499.00</td>\n",
       "      <td>1998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>577.927331</td>\n",
       "      <td>3.0</td>\n",
       "      <td>502.00</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1500.00</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>500.0</td>\n",
       "      <td>1252.5</td>\n",
       "      <td>722.409164</td>\n",
       "      <td>5.0</td>\n",
       "      <td>628.75</td>\n",
       "      <td>1252.5</td>\n",
       "      <td>1876.25</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count    mean         std  min     25%     50%      75%     max\n",
       "0       500.0   998.0  577.927331  0.0  499.00   998.0  1497.00  1996.0\n",
       "1       500.0   999.0  577.927331  1.0  500.00   999.0  1498.00  1997.0\n",
       "2       500.0  1000.0  577.927331  2.0  501.00  1000.0  1499.00  1998.0\n",
       "3       500.0  1001.0  577.927331  3.0  502.00  1001.0  1500.00  1999.0\n",
       "target  500.0  1252.5  722.409164  5.0  628.75  1252.5  1876.25  2500.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats = temp.describe()\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "  return (x - train_stats['mean']) / train_stats['std']\n",
    "normed_train_data = norm(train_dataset)\n",
    "normed_test_data = norm(test_dataset)\n",
    "normed_train_target=normed_train_data.pop('target')\n",
    "normed_test_target=normed_test_data.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/240\n",
      " 1/32 [..............................] - ETA: 0s - loss: 1.0224 - mae: 0.7670 - mse: 1.0224WARNING:tensorflow:From C:\\Users\\sudhe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 2/32 [>.............................] - ETA: 5s - loss: 1.0249 - mae: 0.8150 - mse: 1.0249WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_begin` time: 0.0050s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.3638s). Check your callbacks.\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 0.8075 - mae: 0.7699 - mse: 0.8075 - val_loss: 0.6079 - val_mae: 0.6642 - val_mse: 0.6079\n",
      "Epoch 2/240\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.4356 - mae: 0.5604 - mse: 0.4356 - val_loss: 0.2573 - val_mae: 0.4190 - val_mse: 0.2573\n",
      "Epoch 3/240\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1248 - mae: 0.2741 - mse: 0.1248 - val_loss: 0.0310 - val_mae: 0.1293 - val_mse: 0.0310\n",
      "Epoch 4/240\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0114 - mae: 0.0758 - mse: 0.0114 - val_loss: 0.0025 - val_mae: 0.0406 - val_mse: 0.0025\n",
      "Epoch 5/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0027 - mae: 0.0408 - mse: 0.0027 - val_loss: 0.0022 - val_mae: 0.0376 - val_mse: 0.0022\n",
      "Epoch 6/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0023 - mae: 0.0383 - mse: 0.0023 - val_loss: 0.0018 - val_mae: 0.0341 - val_mse: 0.0018\n",
      "Epoch 7/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0335 - mse: 0.0017 - val_loss: 0.0012 - val_mae: 0.0293 - val_mse: 0.0012\n",
      "Epoch 8/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0012 - mae: 0.0288 - mse: 0.0012 - val_loss: 9.8453e-04 - val_mae: 0.0256 - val_mse: 9.8453e-04\n",
      "Epoch 9/240\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.4344e-04 - mae: 0.0252 - mse: 9.4344e-04 - val_loss: 7.8175e-04 - val_mae: 0.0229 - val_mse: 7.8175e-04\n",
      "Epoch 10/240\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.6028e-04 - mae: 0.0225 - mse: 7.6028e-04 - val_loss: 6.4791e-04 - val_mae: 0.0212 - val_mse: 6.4791e-04\n",
      "Epoch 11/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.2128e-04 - mae: 0.0207 - mse: 6.2128e-04 - val_loss: 5.7688e-04 - val_mae: 0.0199 - val_mse: 5.7688e-04\n",
      "Epoch 12/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.1007e-04 - mae: 0.0146 - mse: 3.1007e-04 - val_loss: 2.5575e-04 - val_mae: 0.0131 - val_mse: 2.5575e-04\n",
      "Epoch 13/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2271e-04 - mae: 0.0089 - mse: 1.2271e-04 - val_loss: 1.2376e-04 - val_mae: 0.0079 - val_mse: 1.2376e-04\n",
      "Epoch 14/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8345e-05 - mae: 0.0056 - mse: 5.8345e-05 - val_loss: 7.0509e-05 - val_mae: 0.0056 - val_mse: 7.0509e-05\n",
      "Epoch 15/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0020e-05 - mae: 0.0038 - mse: 3.0020e-05 - val_loss: 4.3261e-05 - val_mae: 0.0040 - val_mse: 4.3261e-05\n",
      "Epoch 16/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.7693e-05 - mae: 0.0027 - mse: 1.7693e-05 - val_loss: 2.8685e-05 - val_mae: 0.0031 - val_mse: 2.8685e-05\n",
      "Epoch 17/240\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.2002e-05 - mae: 0.0020 - mse: 1.2002e-05 - val_loss: 2.0887e-05 - val_mae: 0.0024 - val_mse: 2.0887e-05\n",
      "Epoch 18/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.7419e-06 - mae: 0.0017 - mse: 8.7419e-06 - val_loss: 1.6017e-05 - val_mae: 0.0021 - val_mse: 1.6017e-05\n",
      "Epoch 19/240\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.1899e-06 - mae: 0.0016 - mse: 7.1899e-06 - val_loss: 1.3139e-05 - val_mae: 0.0020 - val_mse: 1.3139e-05\n",
      "Epoch 20/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.7044e-06 - mae: 0.0017 - mse: 6.7044e-06 - val_loss: 1.1072e-05 - val_mae: 0.0020 - val_mse: 1.1072e-05\n",
      "Epoch 21/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.0226e-06 - mae: 0.0017 - mse: 6.0226e-06 - val_loss: 9.7933e-06 - val_mae: 0.0018 - val_mse: 9.7933e-06\n",
      "Epoch 22/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5097e-06 - mae: 0.0017 - mse: 5.5097e-06 - val_loss: 8.7042e-06 - val_mae: 0.0018 - val_mse: 8.7042e-06\n",
      "Epoch 23/240\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.0309e-06 - mae: 0.0016 - mse: 5.0309e-06 - val_loss: 8.5153e-06 - val_mae: 0.0019 - val_mse: 8.5153e-06\n",
      "Epoch 24/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.2087e-06 - mae: 0.0017 - mse: 5.2087e-06 - val_loss: 7.3668e-06 - val_mae: 0.0016 - val_mse: 7.3668e-06\n",
      "Epoch 25/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.7777e-06 - mae: 0.0016 - mse: 4.7777e-06 - val_loss: 7.6138e-06 - val_mae: 0.0018 - val_mse: 7.6138e-06\n",
      "Epoch 26/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4529e-06 - mae: 0.0018 - mse: 5.4529e-06 - val_loss: 8.9862e-06 - val_mae: 0.0022 - val_mse: 8.9862e-06\n",
      "Epoch 27/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.5819e-06 - mae: 0.0016 - mse: 4.5819e-06 - val_loss: 6.2705e-06 - val_mae: 0.0017 - val_mse: 6.2705e-06\n",
      "Epoch 28/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.7757e-06 - mae: 0.0014 - mse: 3.7757e-06 - val_loss: 5.6008e-06 - val_mae: 0.0015 - val_mse: 5.6008e-06\n",
      "Epoch 29/240\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.6854e-06 - mae: 0.0014 - mse: 3.6854e-06 - val_loss: 5.3779e-06 - val_mae: 0.0015 - val_mse: 5.3779e-06\n",
      "Epoch 30/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1362e-06 - mae: 0.0015 - mse: 4.1362e-06 - val_loss: 5.0680e-06 - val_mae: 0.0015 - val_mse: 5.0680e-06\n",
      "Epoch 31/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4973e-06 - mae: 0.0013 - mse: 3.4973e-06 - val_loss: 4.6080e-06 - val_mae: 0.0014 - val_mse: 4.6080e-06\n",
      "Epoch 32/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3056e-06 - mae: 0.0013 - mse: 3.3056e-06 - val_loss: 4.6083e-06 - val_mae: 0.0015 - val_mse: 4.6083e-06\n",
      "Epoch 33/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.1789e-06 - mae: 0.0013 - mse: 3.1789e-06 - val_loss: 4.3241e-06 - val_mae: 0.0014 - val_mse: 4.3241e-06\n",
      "Epoch 34/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.3256e-06 - mae: 0.0013 - mse: 3.3256e-06 - val_loss: 4.0239e-06 - val_mae: 0.0013 - val_mse: 4.0239e-06\n",
      "Epoch 35/240\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.8579e-06 - mae: 0.0012 - mse: 2.8579e-06 - val_loss: 4.0709e-06 - val_mae: 0.0014 - val_mse: 4.0709e-06\n",
      "Epoch 36/240\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.9182e-06 - mae: 0.0012 - mse: 2.9182e-06 - val_loss: 3.7644e-06 - val_mae: 0.0013 - val_mse: 3.7644e-06\n",
      "Epoch 37/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.9639e-06 - mae: 0.0013 - mse: 2.9639e-06 - val_loss: 3.5691e-06 - val_mae: 0.0013 - val_mse: 3.5691e-06\n",
      "Epoch 38/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.8174e-06 - mae: 0.0012 - mse: 2.8174e-06 - val_loss: 3.4199e-06 - val_mae: 0.0013 - val_mse: 3.4199e-06\n",
      "Epoch 39/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.7522e-06 - mae: 0.0012 - mse: 2.7522e-06 - val_loss: 3.1425e-06 - val_mae: 0.0012 - val_mse: 3.1425e-06\n",
      "Epoch 40/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2679e-06 - mae: 0.0014 - mse: 3.2679e-06 - val_loss: 3.2081e-06 - val_mae: 0.0012 - val_mse: 3.2081e-06\n",
      "Epoch 41/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.7136e-06 - mae: 0.0012 - mse: 2.7136e-06 - val_loss: 2.8957e-06 - val_mae: 0.0011 - val_mse: 2.8957e-06\n",
      "Epoch 42/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.4645e-06 - mae: 0.0011 - mse: 2.4645e-06 - val_loss: 2.9322e-06 - val_mae: 0.0012 - val_mse: 2.9322e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.5634e-06 - mae: 0.0012 - mse: 2.5634e-06 - val_loss: 2.8506e-06 - val_mae: 0.0012 - val_mse: 2.8506e-06\n",
      "Epoch 44/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.2825e-06 - mae: 0.0011 - mse: 2.2825e-06 - val_loss: 2.4683e-06 - val_mae: 0.0011 - val_mse: 2.4683e-06\n",
      "Epoch 45/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.4381e-06 - mae: 0.0011 - mse: 2.4381e-06 - val_loss: 2.4545e-06 - val_mae: 0.0011 - val_mse: 2.4545e-06\n",
      "Epoch 46/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.1174e-06 - mae: 0.0010 - mse: 2.1174e-06 - val_loss: 2.3352e-06 - val_mae: 0.0010 - val_mse: 2.3352e-06\n",
      "Epoch 47/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.1968e-06 - mae: 0.0011 - mse: 2.1968e-06 - val_loss: 2.2885e-06 - val_mae: 0.0011 - val_mse: 2.2885e-06\n",
      "Epoch 48/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.0030e-06 - mae: 0.0010 - mse: 2.0030e-06 - val_loss: 2.1216e-06 - val_mae: 0.0010 - val_mse: 2.1216e-06\n",
      "Epoch 49/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.9957e-06 - mae: 0.0010 - mse: 1.9957e-06 - val_loss: 2.0301e-06 - val_mae: 9.5190e-04 - val_mse: 2.0301e-06\n",
      "Epoch 50/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.1699e-06 - mae: 0.0011 - mse: 2.1699e-06 - val_loss: 2.5530e-06 - val_mae: 0.0013 - val_mse: 2.5530e-06\n",
      "Epoch 51/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.3343e-06 - mae: 0.0012 - mse: 2.3343e-06 - val_loss: 2.5103e-06 - val_mae: 0.0013 - val_mse: 2.5103e-06\n",
      "Epoch 52/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.2224e-06 - mae: 0.0011 - mse: 2.2224e-06 - val_loss: 2.3782e-06 - val_mae: 0.0011 - val_mse: 2.3782e-06\n",
      "Epoch 53/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.2465e-06 - mae: 0.0013 - mse: 3.2465e-06 - val_loss: 2.1849e-06 - val_mae: 0.0011 - val_mse: 2.1849e-06\n",
      "Epoch 54/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.8970e-06 - mae: 0.0010 - mse: 1.8970e-06 - val_loss: 1.7126e-06 - val_mae: 9.1269e-04 - val_mse: 1.7126e-06\n",
      "Epoch 55/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.6325e-06 - mae: 8.9837e-04 - mse: 1.6325e-06 - val_loss: 1.6927e-06 - val_mae: 8.9889e-04 - val_mse: 1.6927e-06\n",
      "Epoch 56/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.7911e-06 - mae: 9.7384e-04 - mse: 1.7911e-06 - val_loss: 1.5885e-06 - val_mae: 8.5437e-04 - val_mse: 1.5885e-06\n",
      "Epoch 57/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.7445e-06 - mae: 9.5145e-04 - mse: 1.7445e-06 - val_loss: 1.5701e-06 - val_mae: 8.8115e-04 - val_mse: 1.5701e-06\n",
      "Epoch 58/240\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4583e-06 - mae: 8.3843e-04 - mse: 1.4583e-06 - val_loss: 1.8871e-06 - val_mae: 0.0010 - val_mse: 1.8871e-06\n",
      "Epoch 59/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.5399e-06 - mae: 8.9297e-04 - mse: 1.5399e-06 - val_loss: 1.4736e-06 - val_mae: 8.2211e-04 - val_mse: 1.4736e-06\n",
      "Epoch 60/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4692e-06 - mae: 8.4349e-04 - mse: 1.4692e-06 - val_loss: 2.0436e-06 - val_mae: 0.0011 - val_mse: 2.0436e-06\n",
      "Epoch 61/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.6961e-06 - mae: 9.3822e-04 - mse: 1.6961e-06 - val_loss: 1.3580e-06 - val_mae: 8.1670e-04 - val_mse: 1.3580e-06\n",
      "Epoch 62/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3348e-06 - mae: 8.1525e-04 - mse: 1.3348e-06 - val_loss: 1.4743e-06 - val_mae: 8.7105e-04 - val_mse: 1.4743e-06\n",
      "Epoch 63/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3629e-06 - mae: 8.2436e-04 - mse: 1.3629e-06 - val_loss: 1.4913e-06 - val_mae: 8.8131e-04 - val_mse: 1.4913e-06\n",
      "Epoch 64/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3809e-06 - mae: 8.5600e-04 - mse: 1.3809e-06 - val_loss: 1.5282e-06 - val_mae: 9.3253e-04 - val_mse: 1.5282e-06\n",
      "Epoch 65/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.5150e-06 - mae: 9.3607e-04 - mse: 1.5150e-06 - val_loss: 1.2516e-06 - val_mae: 7.9553e-04 - val_mse: 1.2516e-06\n",
      "Epoch 66/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2944e-06 - mae: 8.1442e-04 - mse: 1.2944e-06 - val_loss: 1.2473e-06 - val_mae: 7.8546e-04 - val_mse: 1.2473e-06\n",
      "Epoch 67/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.6264e-06 - mae: 9.5473e-04 - mse: 1.6264e-06 - val_loss: 1.9919e-06 - val_mae: 0.0011 - val_mse: 1.9919e-06\n",
      "Epoch 68/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.7075e-06 - mae: 9.5089e-04 - mse: 1.7075e-06 - val_loss: 1.8370e-06 - val_mae: 9.8385e-04 - val_mse: 1.8370e-06\n",
      "Epoch 69/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1764e-06 - mae: 7.5096e-04 - mse: 1.1764e-06 - val_loss: 1.1222e-06 - val_mae: 7.4305e-04 - val_mse: 1.1222e-06\n",
      "Epoch 70/240\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 1.1430e-06 - mae: 7.6067e-04 - mse: 1.1430e-06 - val_loss: 1.0999e-06 - val_mae: 7.1347e-04 - val_mse: 1.0999e-06\n",
      "Epoch 71/240\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0504e-06 - mae: 7.1230e-04 - mse: 1.0504e-06 - val_loss: 1.1121e-06 - val_mae: 7.2521e-04 - val_mse: 1.1121e-06\n",
      "Epoch 72/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.1983e-06 - mae: 7.7553e-04 - mse: 1.1983e-06 - val_loss: 9.8958e-07 - val_mae: 6.8560e-04 - val_mse: 9.8958e-07\n",
      "Epoch 73/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0533e-06 - mae: 7.4729e-04 - mse: 1.0533e-06 - val_loss: 1.0304e-06 - val_mae: 7.3765e-04 - val_mse: 1.0304e-06\n",
      "Epoch 74/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3962e-06 - mae: 8.8487e-04 - mse: 1.3962e-06 - val_loss: 1.2417e-06 - val_mae: 8.5570e-04 - val_mse: 1.2417e-06\n",
      "Epoch 75/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3924e-06 - mae: 8.6490e-04 - mse: 1.3924e-06 - val_loss: 1.1523e-06 - val_mae: 8.0330e-04 - val_mse: 1.1523e-06\n",
      "Epoch 76/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1010e-06 - mae: 7.5540e-04 - mse: 1.1010e-06 - val_loss: 1.1722e-06 - val_mae: 7.8917e-04 - val_mse: 1.1722e-06\n",
      "Epoch 77/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4922e-06 - mae: 8.6004e-04 - mse: 1.4922e-06 - val_loss: 2.1007e-06 - val_mae: 0.0010 - val_mse: 2.1007e-06\n",
      "Epoch 78/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3490e-06 - mae: 8.3308e-04 - mse: 1.3490e-06 - val_loss: 8.9381e-07 - val_mae: 6.5055e-04 - val_mse: 8.9381e-07\n",
      "Epoch 79/240\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 9.5803e-07 - mae: 6.9612e-04 - mse: 9.5803e-07 - val_loss: 9.4597e-07 - val_mae: 6.8259e-04 - val_mse: 9.4597e-07\n",
      "Epoch 80/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3218e-06 - mae: 8.0800e-04 - mse: 1.3218e-06 - val_loss: 1.0871e-06 - val_mae: 7.3509e-04 - val_mse: 1.0871e-06\n",
      "Epoch 81/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2784e-06 - mae: 8.2537e-04 - mse: 1.2784e-06 - val_loss: 1.4617e-06 - val_mae: 8.9689e-04 - val_mse: 1.4617e-06\n",
      "Epoch 82/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.1028e-06 - mae: 7.8331e-04 - mse: 1.1028e-06 - val_loss: 9.3448e-07 - val_mae: 7.0048e-04 - val_mse: 9.3448e-07\n",
      "Epoch 83/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2672e-06 - mae: 8.0704e-04 - mse: 1.2672e-06 - val_loss: 2.8088e-06 - val_mae: 0.0012 - val_mse: 2.8088e-06\n",
      "Epoch 84/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.7137e-06 - mae: 9.4080e-04 - mse: 1.7137e-06 - val_loss: 1.5059e-06 - val_mae: 9.1067e-04 - val_mse: 1.5059e-06\n",
      "Epoch 85/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3051e-06 - mae: 8.3818e-04 - mse: 1.3051e-06 - val_loss: 8.9131e-07 - val_mae: 6.3367e-04 - val_mse: 8.9131e-07\n",
      "Epoch 86/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0245e-06 - mae: 7.3671e-04 - mse: 1.0245e-06 - val_loss: 6.1887e-07 - val_mae: 5.3997e-04 - val_mse: 6.1887e-07\n",
      "Epoch 87/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 7.4223e-07 - mae: 6.0502e-04 - mse: 7.4223e-07 - val_loss: 7.6285e-07 - val_mae: 6.3687e-04 - val_mse: 7.6285e-07\n",
      "Epoch 88/240\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 7.1959e-07 - mae: 6.0081e-04 - mse: 7.1959e-07 - val_loss: 5.7667e-07 - val_mae: 4.6870e-04 - val_mse: 5.7667e-07\n",
      "Epoch 89/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.0470e-07 - mae: 5.7142e-04 - mse: 7.0470e-07 - val_loss: 8.6436e-07 - val_mae: 6.4438e-04 - val_mse: 8.6436e-07\n",
      "Epoch 90/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5917e-07 - mae: 6.1387e-04 - mse: 7.5917e-07 - val_loss: 5.6573e-07 - val_mae: 4.8640e-04 - val_mse: 5.6573e-07\n",
      "Epoch 91/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.9169e-07 - mae: 5.7893e-04 - mse: 6.9169e-07 - val_loss: 5.8166e-07 - val_mae: 4.9064e-04 - val_mse: 5.8166e-07\n",
      "Epoch 92/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.2407e-07 - mae: 6.7304e-04 - mse: 8.2407e-07 - val_loss: 7.7829e-07 - val_mae: 6.2199e-04 - val_mse: 7.7829e-07\n",
      "Epoch 93/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.7173e-07 - mae: 5.4445e-04 - mse: 6.7173e-07 - val_loss: 5.7007e-07 - val_mae: 5.0712e-04 - val_mse: 5.7007e-07\n",
      "Epoch 94/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8898e-07 - mae: 5.6978e-04 - mse: 6.8898e-07 - val_loss: 1.0949e-06 - val_mae: 7.3979e-04 - val_mse: 1.0949e-06\n",
      "Epoch 95/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.5627e-07 - mae: 6.0430e-04 - mse: 7.5627e-07 - val_loss: 1.0517e-06 - val_mae: 7.1851e-04 - val_mse: 1.0517e-06\n",
      "Epoch 96/240\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.9258e-07 - mae: 5.7884e-04 - mse: 6.9258e-07 - val_loss: 5.2926e-07 - val_mae: 4.9632e-04 - val_mse: 5.2926e-07\n",
      "Epoch 97/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.9108e-07 - mae: 5.6476e-04 - mse: 6.9108e-07 - val_loss: 5.0379e-07 - val_mae: 4.7527e-04 - val_mse: 5.0379e-07\n",
      "Epoch 98/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.9801e-07 - mae: 5.3661e-04 - mse: 5.9801e-07 - val_loss: 4.7832e-07 - val_mae: 4.7162e-04 - val_mse: 4.7832e-07\n",
      "Epoch 99/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.0558e-07 - mae: 6.6960e-04 - mse: 8.0558e-07 - val_loss: 5.5254e-07 - val_mae: 5.6052e-04 - val_mse: 5.5254e-07\n",
      "Epoch 100/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.8676e-07 - mae: 6.3782e-04 - mse: 7.8676e-07 - val_loss: 6.6188e-07 - val_mae: 6.0905e-04 - val_mse: 6.6188e-07\n",
      "Epoch 101/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3810e-06 - mae: 8.6776e-04 - mse: 1.3810e-06 - val_loss: 4.4385e-07 - val_mae: 4.5064e-04 - val_mse: 4.4385e-07\n",
      "Epoch 102/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7214e-07 - mae: 5.1210e-04 - mse: 5.7214e-07 - val_loss: 4.4017e-07 - val_mae: 4.2345e-04 - val_mse: 4.4017e-07\n",
      "Epoch 103/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.3678e-07 - mae: 6.2229e-04 - mse: 7.3678e-07 - val_loss: 6.4220e-07 - val_mae: 6.8016e-04 - val_mse: 6.4220e-07\n",
      "Epoch 104/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.9517e-07 - mae: 4.7173e-04 - mse: 4.9517e-07 - val_loss: 4.1185e-07 - val_mae: 4.0690e-04 - val_mse: 4.1185e-07\n",
      "Epoch 105/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.1240e-07 - mae: 4.8944e-04 - mse: 5.1240e-07 - val_loss: 5.2899e-07 - val_mae: 5.0833e-04 - val_mse: 5.2899e-07\n",
      "Epoch 106/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0701e-06 - mae: 7.1099e-04 - mse: 1.0701e-06 - val_loss: 4.1600e-07 - val_mae: 4.3159e-04 - val_mse: 4.1600e-07\n",
      "Epoch 107/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.2156e-07 - mae: 4.8064e-04 - mse: 5.2156e-07 - val_loss: 4.3395e-07 - val_mae: 4.6432e-04 - val_mse: 4.3395e-07\n",
      "Epoch 108/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.1826e-07 - mae: 3.9412e-04 - mse: 4.1826e-07 - val_loss: 4.0352e-07 - val_mae: 4.1971e-04 - val_mse: 4.0352e-07\n",
      "Epoch 109/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0166e-07 - mae: 3.8343e-04 - mse: 4.0166e-07 - val_loss: 3.9382e-07 - val_mae: 3.9817e-04 - val_mse: 3.9382e-07\n",
      "Epoch 110/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2412e-07 - mae: 4.0927e-04 - mse: 4.2412e-07 - val_loss: 3.7813e-07 - val_mae: 3.7469e-04 - val_mse: 3.7813e-07\n",
      "Epoch 111/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.8740e-07 - mae: 5.7705e-04 - mse: 6.8740e-07 - val_loss: 2.0008e-06 - val_mae: 0.0010 - val_mse: 2.0008e-06\n",
      "Epoch 112/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.1074e-07 - mae: 5.5782e-04 - mse: 7.1074e-07 - val_loss: 3.9603e-07 - val_mae: 3.8841e-04 - val_mse: 3.9603e-07\n",
      "Epoch 113/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0840e-07 - mae: 3.9460e-04 - mse: 4.0840e-07 - val_loss: 3.9018e-07 - val_mae: 3.7952e-04 - val_mse: 3.9018e-07\n",
      "Epoch 114/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.0164e-07 - mae: 6.1115e-04 - mse: 8.0164e-07 - val_loss: 1.8188e-06 - val_mae: 0.0011 - val_mse: 1.8188e-06\n",
      "Epoch 115/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.8743e-06 - mae: 0.0014 - mse: 3.8743e-06 - val_loss: 8.8328e-07 - val_mae: 6.2765e-04 - val_mse: 8.8328e-07\n",
      "Epoch 116/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4603e-07 - mae: 3.8544e-04 - mse: 4.4603e-07 - val_loss: 4.5077e-07 - val_mae: 4.8590e-04 - val_mse: 4.5077e-07\n",
      "Epoch 117/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.6558e-07 - mae: 4.5143e-04 - mse: 4.6558e-07 - val_loss: 5.8478e-07 - val_mae: 6.4069e-04 - val_mse: 5.8478e-07\n",
      "Epoch 118/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.5326e-07 - mae: 5.0626e-04 - mse: 5.5326e-07 - val_loss: 4.4504e-07 - val_mae: 4.6497e-04 - val_mse: 4.4504e-07\n",
      "Epoch 119/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5954e-07 - mae: 3.7687e-04 - mse: 3.5954e-07 - val_loss: 3.8920e-07 - val_mae: 4.0439e-04 - val_mse: 3.8920e-07\n",
      "Epoch 120/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.5051e-07 - mae: 5.2827e-04 - mse: 6.5051e-07 - val_loss: 4.8774e-07 - val_mae: 4.9705e-04 - val_mse: 4.8774e-07\n",
      "Epoch 121/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.7101e-07 - mae: 5.1334e-04 - mse: 5.7101e-07 - val_loss: 2.5166e-06 - val_mae: 0.0012 - val_mse: 2.5166e-06\n",
      "Epoch 122/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.4991e-07 - mae: 6.3638e-04 - mse: 8.4991e-07 - val_loss: 1.1660e-06 - val_mae: 8.1352e-04 - val_mse: 1.1660e-06\n",
      "Epoch 123/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.5443e-07 - mae: 6.3488e-04 - mse: 7.5443e-07 - val_loss: 1.1460e-06 - val_mae: 9.5807e-04 - val_mse: 1.1460e-06\n",
      "Epoch 124/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.7442e-06 - mae: 0.0010 - mse: 1.7442e-06 - val_loss: 1.5714e-06 - val_mae: 9.4811e-04 - val_mse: 1.5714e-06\n",
      "Epoch 125/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.8175e-07 - mae: 6.0896e-04 - mse: 9.8175e-07 - val_loss: 3.2005e-07 - val_mae: 3.3561e-04 - val_mse: 3.2005e-07\n",
      "Epoch 126/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.8888e-07 - mae: 3.1087e-04 - mse: 2.8888e-07 - val_loss: 4.2332e-07 - val_mae: 5.1771e-04 - val_mse: 4.2332e-07\n",
      "Epoch 127/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.8457e-07 - mae: 5.3371e-04 - mse: 5.8457e-07 - val_loss: 3.4435e-07 - val_mae: 4.1102e-04 - val_mse: 3.4435e-07\n",
      "Epoch 128/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.7004e-07 - mae: 4.8380e-04 - mse: 4.7004e-07 - val_loss: 9.5566e-07 - val_mae: 8.0165e-04 - val_mse: 9.5566e-07\n",
      "Epoch 129/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0624e-07 - mae: 3.9491e-04 - mse: 4.0624e-07 - val_loss: 3.2187e-07 - val_mae: 3.7778e-04 - val_mse: 3.2187e-07\n",
      "Epoch 130/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 2.8826e-07 - mae: 3.2227e-04 - mse: 2.8826e-07 - val_loss: 2.9890e-07 - val_mae: 3.3038e-04 - val_mse: 2.9890e-07\n",
      "Epoch 131/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.4784e-07 - mae: 4.6874e-04 - mse: 4.4784e-07 - val_loss: 7.6288e-07 - val_mae: 7.5380e-04 - val_mse: 7.6288e-07\n",
      "Epoch 132/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.1430e-07 - mae: 6.2908e-04 - mse: 7.1430e-07 - val_loss: 7.2546e-07 - val_mae: 7.3392e-04 - val_mse: 7.2546e-07\n",
      "Epoch 133/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.3614e-07 - mae: 5.8789e-04 - mse: 7.3614e-07 - val_loss: 3.1491e-06 - val_mae: 0.0015 - val_mse: 3.1491e-06\n",
      "Epoch 134/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.7555e-07 - mae: 6.4412e-04 - mse: 8.7555e-07 - val_loss: 2.9276e-07 - val_mae: 3.7062e-04 - val_mse: 2.9276e-07\n",
      "Epoch 135/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.8744e-07 - mae: 3.9942e-04 - mse: 3.8744e-07 - val_loss: 6.1035e-07 - val_mae: 5.5375e-04 - val_mse: 6.1035e-07\n",
      "Epoch 136/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.1094e-07 - mae: 6.9862e-04 - mse: 9.1094e-07 - val_loss: 6.4426e-07 - val_mae: 6.6049e-04 - val_mse: 6.4426e-07\n",
      "Epoch 137/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3290e-06 - mae: 8.5825e-04 - mse: 1.3290e-06 - val_loss: 5.0675e-07 - val_mae: 6.0213e-04 - val_mse: 5.0675e-07\n",
      "Epoch 138/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.0577e-07 - mae: 4.1461e-04 - mse: 4.0577e-07 - val_loss: 4.9569e-07 - val_mae: 5.4495e-04 - val_mse: 4.9569e-07\n",
      "Epoch 139/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3651e-06 - mae: 8.1265e-04 - mse: 1.3651e-06 - val_loss: 6.1129e-07 - val_mae: 5.8506e-04 - val_mse: 6.1129e-07\n",
      "Epoch 140/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.6305e-07 - mae: 4.3012e-04 - mse: 3.6305e-07 - val_loss: 3.5490e-07 - val_mae: 4.2046e-04 - val_mse: 3.5490e-07\n",
      "Epoch 141/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.3315e-07 - mae: 3.8668e-04 - mse: 3.3315e-07 - val_loss: 3.7828e-07 - val_mae: 4.8356e-04 - val_mse: 3.7828e-07\n",
      "Epoch 142/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 7.4973e-07 - mae: 5.9796e-04 - mse: 7.4973e-07 - val_loss: 5.4445e-07 - val_mae: 5.6881e-04 - val_mse: 5.4445e-07\n",
      "Epoch 143/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.1796e-06 - mae: 0.0011 - mse: 2.1796e-06 - val_loss: 1.0976e-06 - val_mae: 9.5142e-04 - val_mse: 1.0976e-06\n",
      "Epoch 144/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.4255e-07 - mae: 7.4293e-04 - mse: 9.4255e-07 - val_loss: 4.7249e-07 - val_mae: 5.9442e-04 - val_mse: 4.7249e-07\n",
      "Epoch 145/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.6866e-07 - mae: 3.3512e-04 - mse: 2.6866e-07 - val_loss: 2.7344e-07 - val_mae: 3.7831e-04 - val_mse: 2.7344e-07\n",
      "Epoch 146/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.5631e-07 - mae: 3.2292e-04 - mse: 2.5631e-07 - val_loss: 3.5857e-07 - val_mae: 4.4306e-04 - val_mse: 3.5857e-07\n",
      "Epoch 147/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.3322e-07 - mae: 4.0433e-04 - mse: 3.3322e-07 - val_loss: 1.1581e-06 - val_mae: 9.0342e-04 - val_mse: 1.1581e-06\n",
      "Epoch 148/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1637e-06 - mae: 7.7309e-04 - mse: 1.1637e-06 - val_loss: 9.6547e-07 - val_mae: 8.3875e-04 - val_mse: 9.6547e-07\n",
      "Epoch 149/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.8699e-06 - mae: 9.5990e-04 - mse: 1.8699e-06 - val_loss: 2.0053e-07 - val_mae: 2.6144e-04 - val_mse: 2.0053e-07\n",
      "Epoch 150/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.1111e-07 - mae: 2.5784e-04 - mse: 2.1111e-07 - val_loss: 4.2202e-07 - val_mae: 4.7353e-04 - val_mse: 4.2202e-07\n",
      "Epoch 151/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.9174e-07 - mae: 4.1535e-04 - mse: 3.9174e-07 - val_loss: 1.9174e-07 - val_mae: 2.3324e-04 - val_mse: 1.9174e-07\n",
      "Epoch 152/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.4793e-06 - mae: 0.0011 - mse: 2.4793e-06 - val_loss: 3.9349e-07 - val_mae: 4.6053e-04 - val_mse: 3.9349e-07\n",
      "Epoch 153/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.4876e-06 - mae: 0.0011 - mse: 2.4876e-06 - val_loss: 3.0840e-06 - val_mae: 0.0013 - val_mse: 3.0840e-06\n",
      "Epoch 154/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.5415e-06 - mae: 0.0015 - mse: 4.5415e-06 - val_loss: 4.9452e-06 - val_mae: 0.0019 - val_mse: 4.9452e-06\n",
      "Epoch 155/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0285e-05 - mae: 0.0023 - mse: 1.0285e-05 - val_loss: 2.1563e-06 - val_mae: 9.1424e-04 - val_mse: 2.1563e-06\n",
      "Epoch 156/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.2455e-06 - mae: 0.0016 - mse: 4.2455e-06 - val_loss: 6.0947e-06 - val_mae: 0.0022 - val_mse: 6.0947e-06\n",
      "Epoch 157/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9053e-06 - mae: 0.0015 - mse: 3.9053e-06 - val_loss: 5.8643e-07 - val_mae: 5.9592e-04 - val_mse: 5.8643e-07\n",
      "Epoch 158/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1178e-06 - mae: 8.0866e-04 - mse: 1.1178e-06 - val_loss: 7.8253e-07 - val_mae: 7.5800e-04 - val_mse: 7.8253e-07\n",
      "Epoch 159/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.2261e-07 - mae: 4.7547e-04 - mse: 4.2261e-07 - val_loss: 9.7247e-07 - val_mae: 7.2208e-04 - val_mse: 9.7247e-07\n",
      "Epoch 160/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.6531e-06 - mae: 9.5867e-04 - mse: 1.6531e-06 - val_loss: 5.7300e-06 - val_mae: 0.0017 - val_mse: 5.7300e-06\n",
      "Epoch 161/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.3160e-06 - mae: 0.0013 - mse: 3.3160e-06 - val_loss: 1.7233e-06 - val_mae: 0.0011 - val_mse: 1.7233e-06\n",
      "Epoch 162/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.4461e-07 - mae: 6.7257e-04 - mse: 8.4461e-07 - val_loss: 4.7062e-07 - val_mae: 5.3458e-04 - val_mse: 4.7062e-07\n",
      "Epoch 163/240\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.1562e-07 - mae: 6.8895e-04 - mse: 9.1562e-07 - val_loss: 4.2026e-06 - val_mae: 0.0014 - val_mse: 4.2026e-06\n",
      "Epoch 164/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.8463e-06 - mae: 0.0016 - mse: 4.8463e-06 - val_loss: 5.7457e-06 - val_mae: 0.0018 - val_mse: 5.7457e-06\n",
      "Epoch 165/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.2443e-06 - mae: 0.0016 - mse: 5.2443e-06 - val_loss: 4.0947e-06 - val_mae: 0.0017 - val_mse: 4.0947e-06\n",
      "Epoch 166/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.7678e-07 - mae: 6.2872e-04 - mse: 7.7678e-07 - val_loss: 5.8486e-07 - val_mae: 6.5103e-04 - val_mse: 5.8486e-07\n",
      "Epoch 167/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.4981e-07 - mae: 3.0991e-04 - mse: 2.4981e-07 - val_loss: 2.1186e-07 - val_mae: 2.6447e-04 - val_mse: 2.1186e-07\n",
      "Epoch 168/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5414e-07 - mae: 2.4235e-04 - mse: 1.5414e-07 - val_loss: 1.9662e-07 - val_mae: 2.3586e-04 - val_mse: 1.9662e-07\n",
      "Epoch 169/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2850e-07 - mae: 2.0634e-04 - mse: 1.2850e-07 - val_loss: 2.1003e-07 - val_mae: 3.2847e-04 - val_mse: 2.1003e-07\n",
      "Epoch 170/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.5327e-07 - mae: 2.5428e-04 - mse: 1.5327e-07 - val_loss: 2.1892e-07 - val_mae: 2.9641e-04 - val_mse: 2.1892e-07\n",
      "Epoch 171/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4866e-07 - mae: 2.4463e-04 - mse: 1.4866e-07 - val_loss: 2.0974e-07 - val_mae: 2.5026e-04 - val_mse: 2.0974e-07\n",
      "Epoch 172/240\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.1897e-07 - mae: 2.0835e-04 - mse: 1.1897e-07 - val_loss: 2.0494e-07 - val_mae: 3.0542e-04 - val_mse: 2.0494e-07\n",
      "Epoch 173/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.8458e-07 - mae: 3.4617e-04 - mse: 2.8458e-07 - val_loss: 1.5522e-07 - val_mae: 1.9748e-04 - val_mse: 1.5522e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.4542e-07 - mae: 4.3435e-04 - mse: 3.4542e-07 - val_loss: 6.0772e-07 - val_mae: 6.4148e-04 - val_mse: 6.0772e-07\n",
      "Epoch 175/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.0811e-06 - mae: 0.0011 - mse: 3.0811e-06 - val_loss: 4.8041e-06 - val_mae: 0.0016 - val_mse: 4.8041e-06\n",
      "Epoch 176/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.5491e-05 - mae: 0.0035 - mse: 2.5491e-05 - val_loss: 1.2093e-04 - val_mae: 0.0072 - val_mse: 1.2093e-04\n",
      "Epoch 177/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.1902e-04 - mae: 0.0095 - mse: 2.1902e-04 - val_loss: 9.7552e-05 - val_mae: 0.0080 - val_mse: 9.7552e-05\n",
      "Epoch 178/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.3096e-05 - mae: 0.0074 - mse: 8.3096e-05 - val_loss: 7.0132e-05 - val_mae: 0.0059 - val_mse: 7.0132e-05\n",
      "Epoch 179/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.9924e-05 - mae: 0.0039 - mse: 2.9924e-05 - val_loss: 1.8902e-05 - val_mae: 0.0037 - val_mse: 1.8902e-05\n",
      "Epoch 180/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.2388e-06 - mae: 0.0018 - mse: 6.2388e-06 - val_loss: 1.1454e-05 - val_mae: 0.0028 - val_mse: 1.1454e-05\n",
      "Epoch 181/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.7634e-06 - mae: 0.0023 - mse: 9.7634e-06 - val_loss: 1.7813e-05 - val_mae: 0.0029 - val_mse: 1.7813e-05\n",
      "Epoch 182/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.4253e-06 - mae: 0.0018 - mse: 6.4253e-06 - val_loss: 1.6616e-06 - val_mae: 0.0010 - val_mse: 1.6616e-06\n",
      "Epoch 183/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.2907e-06 - mae: 0.0022 - mse: 9.2907e-06 - val_loss: 2.8209e-06 - val_mae: 0.0013 - val_mse: 2.8209e-06\n",
      "Epoch 184/240\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.4640e-06 - mae: 0.0017 - mse: 4.4640e-06 - val_loss: 4.6078e-06 - val_mae: 0.0015 - val_mse: 4.6078e-06\n",
      "Epoch 185/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2333e-06 - mae: 7.7808e-04 - mse: 1.2333e-06 - val_loss: 4.7746e-07 - val_mae: 5.7729e-04 - val_mse: 4.7746e-07\n",
      "Epoch 186/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.2320e-07 - mae: 3.3393e-04 - mse: 2.2320e-07 - val_loss: 1.6656e-07 - val_mae: 2.9207e-04 - val_mse: 1.6656e-07\n",
      "Epoch 187/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.4316e-07 - mae: 2.3773e-04 - mse: 1.4316e-07 - val_loss: 1.1552e-07 - val_mae: 2.0423e-04 - val_mse: 1.1552e-07\n",
      "Epoch 188/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.1789e-07 - mae: 2.0034e-04 - mse: 1.1789e-07 - val_loss: 1.2383e-07 - val_mae: 1.8341e-04 - val_mse: 1.2383e-07\n",
      "Epoch 189/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.7984e-07 - mae: 2.9049e-04 - mse: 1.7984e-07 - val_loss: 2.5157e-07 - val_mae: 4.1270e-04 - val_mse: 2.5157e-07\n",
      "Epoch 190/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3527e-07 - mae: 2.3646e-04 - mse: 1.3527e-07 - val_loss: 1.1720e-07 - val_mae: 1.8696e-04 - val_mse: 1.1720e-07\n",
      "Epoch 191/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.6267e-07 - mae: 3.4896e-04 - mse: 2.6267e-07 - val_loss: 3.1748e-07 - val_mae: 4.8679e-04 - val_mse: 3.1748e-07\n",
      "Epoch 192/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.8745e-07 - mae: 5.0749e-04 - mse: 4.8745e-07 - val_loss: 1.3563e-06 - val_mae: 0.0011 - val_mse: 1.3563e-06\n",
      "Epoch 193/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.1672e-06 - mae: 0.0010 - mse: 2.1672e-06 - val_loss: 8.3009e-07 - val_mae: 7.9095e-04 - val_mse: 8.3009e-07\n",
      "Epoch 194/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7520e-07 - mae: 6.1367e-04 - mse: 5.7520e-07 - val_loss: 1.0505e-06 - val_mae: 8.9124e-04 - val_mse: 1.0505e-06\n",
      "Epoch 195/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 9.3514e-07 - mae: 7.4037e-04 - mse: 9.3514e-07 - val_loss: 7.5591e-07 - val_mae: 7.4129e-04 - val_mse: 7.5591e-07\n",
      "Epoch 196/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4336e-07 - mae: 5.6607e-04 - mse: 5.4336e-07 - val_loss: 4.7999e-07 - val_mae: 6.0315e-04 - val_mse: 4.7999e-07\n",
      "Epoch 197/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.8976e-07 - mae: 3.2066e-04 - mse: 1.8976e-07 - val_loss: 2.5944e-07 - val_mae: 3.7600e-04 - val_mse: 2.5944e-07\n",
      "Epoch 198/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.9874e-06 - mae: 9.5517e-04 - mse: 1.9874e-06 - val_loss: 1.6839e-06 - val_mae: 0.0011 - val_mse: 1.6839e-06\n",
      "Epoch 199/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.4567e-07 - mae: 5.5773e-04 - mse: 5.4567e-07 - val_loss: 2.2857e-07 - val_mae: 3.3713e-04 - val_mse: 2.2857e-07\n",
      "Epoch 200/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3072e-07 - mae: 4.8514e-04 - mse: 4.3072e-07 - val_loss: 2.9214e-07 - val_mae: 4.1552e-04 - val_mse: 2.9214e-07\n",
      "Epoch 201/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.1146e-07 - mae: 4.8797e-04 - mse: 5.1146e-07 - val_loss: 2.5144e-06 - val_mae: 0.0012 - val_mse: 2.5144e-06\n",
      "Epoch 202/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2800e-06 - mae: 7.7772e-04 - mse: 1.2800e-06 - val_loss: 3.0123e-07 - val_mae: 3.7765e-04 - val_mse: 3.0123e-07\n",
      "Epoch 203/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.6873e-07 - mae: 3.1358e-04 - mse: 1.6873e-07 - val_loss: 1.9096e-07 - val_mae: 3.1810e-04 - val_mse: 1.9096e-07\n",
      "Epoch 204/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3716e-07 - mae: 2.5465e-04 - mse: 1.3716e-07 - val_loss: 3.3797e-07 - val_mae: 3.7884e-04 - val_mse: 3.3797e-07\n",
      "Epoch 205/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.6058e-07 - mae: 2.8119e-04 - mse: 1.6058e-07 - val_loss: 1.2920e-07 - val_mae: 2.0733e-04 - val_mse: 1.2920e-07\n",
      "Epoch 206/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.3227e-07 - mae: 2.5745e-04 - mse: 1.3227e-07 - val_loss: 3.6135e-07 - val_mae: 5.0721e-04 - val_mse: 3.6135e-07\n",
      "Epoch 207/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9904e-07 - mae: 4.5186e-04 - mse: 3.9904e-07 - val_loss: 3.8282e-07 - val_mae: 4.7386e-04 - val_mse: 3.8282e-07\n",
      "Epoch 208/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3930e-07 - mae: 5.3604e-04 - mse: 4.3930e-07 - val_loss: 3.5785e-07 - val_mae: 5.0191e-04 - val_mse: 3.5785e-07\n",
      "Epoch 209/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.8891e-06 - mae: 0.0010 - mse: 1.8891e-06 - val_loss: 4.3827e-06 - val_mae: 0.0017 - val_mse: 4.3827e-06\n",
      "Epoch 210/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.8513e-06 - mae: 8.2932e-04 - mse: 1.8513e-06 - val_loss: 1.4201e-07 - val_mae: 2.0108e-04 - val_mse: 1.4201e-07\n",
      "Epoch 211/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0561e-07 - mae: 2.0037e-04 - mse: 1.0561e-07 - val_loss: 1.4948e-07 - val_mae: 2.0887e-04 - val_mse: 1.4948e-07\n",
      "Epoch 212/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.6326e-08 - mae: 1.7930e-04 - mse: 8.6326e-08 - val_loss: 1.3730e-07 - val_mae: 2.2071e-04 - val_mse: 1.3730e-07\n",
      "Epoch 213/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2562e-07 - mae: 2.5955e-04 - mse: 1.2562e-07 - val_loss: 2.1812e-07 - val_mae: 3.1703e-04 - val_mse: 2.1812e-07\n",
      "Epoch 214/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.6730e-07 - mae: 2.8447e-04 - mse: 1.6730e-07 - val_loss: 4.2608e-07 - val_mae: 5.4184e-04 - val_mse: 4.2608e-07\n",
      "Epoch 215/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.7459e-07 - mae: 5.5722e-04 - mse: 5.7459e-07 - val_loss: 7.9680e-06 - val_mae: 0.0020 - val_mse: 7.9680e-06\n",
      "Epoch 216/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.9585e-05 - mae: 0.0048 - mse: 5.9585e-05 - val_loss: 1.8393e-04 - val_mae: 0.0107 - val_mse: 1.8393e-04\n",
      "Epoch 217/240\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.9230e-05 - mae: 0.0063 - mse: 7.9230e-05 - val_loss: 1.3731e-05 - val_mae: 0.0029 - val_mse: 1.3731e-05\n",
      "Epoch 218/240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2116e-05 - mae: 0.0025 - mse: 1.2116e-05 - val_loss: 2.3273e-05 - val_mae: 0.0041 - val_mse: 2.3273e-05\n",
      "Epoch 219/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2762e-05 - mae: 0.0027 - mse: 1.2762e-05 - val_loss: 1.6940e-05 - val_mae: 0.0030 - val_mse: 1.6940e-05\n",
      "Epoch 220/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.1077e-05 - mae: 0.0034 - mse: 3.1077e-05 - val_loss: 1.1383e-04 - val_mae: 0.0083 - val_mse: 1.1383e-04\n",
      "Epoch 221/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.3818e-05 - mae: 0.0043 - mse: 4.3818e-05 - val_loss: 2.5664e-06 - val_mae: 0.0011 - val_mse: 2.5664e-06\n",
      "Epoch 222/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.3741e-06 - mae: 0.0014 - mse: 4.3741e-06 - val_loss: 7.4100e-07 - val_mae: 6.8036e-04 - val_mse: 7.4100e-07\n",
      "Epoch 223/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0065e-06 - mae: 7.6981e-04 - mse: 1.0065e-06 - val_loss: 7.9495e-07 - val_mae: 7.0710e-04 - val_mse: 7.9495e-07\n",
      "Epoch 224/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5710e-07 - mae: 2.8431e-04 - mse: 1.5710e-07 - val_loss: 1.9974e-07 - val_mae: 2.5274e-04 - val_mse: 1.9974e-07\n",
      "Epoch 225/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.5170e-07 - mae: 2.7580e-04 - mse: 1.5170e-07 - val_loss: 1.6565e-07 - val_mae: 2.7853e-04 - val_mse: 1.6565e-07\n",
      "Epoch 226/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.3817e-07 - mae: 3.6713e-04 - mse: 2.3817e-07 - val_loss: 1.9476e-07 - val_mae: 2.0813e-04 - val_mse: 1.9476e-07\n",
      "Epoch 227/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.6729e-07 - mae: 4.2180e-04 - mse: 3.6729e-07 - val_loss: 3.4215e-07 - val_mae: 4.5468e-04 - val_mse: 3.4215e-07\n",
      "Epoch 228/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.6870e-07 - mae: 4.1178e-04 - mse: 3.6870e-07 - val_loss: 1.5863e-07 - val_mae: 2.3650e-04 - val_mse: 1.5863e-07\n",
      "Epoch 229/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.1193e-08 - mae: 1.8422e-04 - mse: 8.1193e-08 - val_loss: 1.3570e-07 - val_mae: 2.0087e-04 - val_mse: 1.3570e-07\n",
      "Epoch 230/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.6068e-08 - mae: 1.4564e-04 - mse: 6.6068e-08 - val_loss: 1.4011e-07 - val_mae: 1.6084e-04 - val_mse: 1.4011e-07\n",
      "Epoch 231/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 8.9364e-08 - mae: 1.8632e-04 - mse: 8.9364e-08 - val_loss: 1.5021e-07 - val_mae: 2.0328e-04 - val_mse: 1.5021e-07\n",
      "Epoch 232/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.8565e-08 - mae: 1.6205e-04 - mse: 6.8565e-08 - val_loss: 1.7471e-07 - val_mae: 2.3468e-04 - val_mse: 1.7471e-07\n",
      "Epoch 233/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.5676e-07 - mae: 2.9634e-04 - mse: 1.5676e-07 - val_loss: 2.3983e-07 - val_mae: 3.8671e-04 - val_mse: 2.3983e-07\n",
      "Epoch 234/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.1209e-06 - mae: 0.0014 - mse: 4.1209e-06 - val_loss: 1.1631e-06 - val_mae: 9.2452e-04 - val_mse: 1.1631e-06\n",
      "Epoch 235/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 4.0343e-06 - mae: 0.0014 - mse: 4.0343e-06 - val_loss: 3.8527e-06 - val_mae: 0.0017 - val_mse: 3.8527e-06\n",
      "Epoch 236/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.9550e-06 - mae: 0.0010 - mse: 1.9550e-06 - val_loss: 1.3170e-06 - val_mae: 9.0368e-04 - val_mse: 1.3170e-06\n",
      "Epoch 237/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.1790e-06 - mae: 0.0010 - mse: 2.1790e-06 - val_loss: 6.9671e-07 - val_mae: 6.0972e-04 - val_mse: 6.9671e-07\n",
      "Epoch 238/240\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.2034e-06 - mae: 0.0019 - mse: 6.2034e-06 - val_loss: 3.7357e-06 - val_mae: 0.0016 - val_mse: 3.7357e-06\n",
      "Epoch 239/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 6.1430e-06 - mae: 0.0019 - mse: 6.1430e-06 - val_loss: 7.1082e-06 - val_mae: 0.0020 - val_mse: 7.1082e-06\n",
      "Epoch 240/240\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2416e-06 - mae: 7.1824e-04 - mse: 1.2416e-06 - val_loss: 1.6254e-07 - val_mae: 1.6651e-04 - val_mse: 1.6254e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x262f6c52e48>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model.fit(normed_train_data,normed_train_target,validation_split=0.2,epochs=240,verbose=1,batch_size=10,callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7936), started 0:11:11 ago. (Use '!kill 7936' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7e7a17375fd6b88b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7e7a17375fd6b88b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=logs/scalars/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 11456."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=logs/scalars/'20200813-061118'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
